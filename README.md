ğŸ§  LangChain Agent with Persistent Memory (Mem0)

A modular, production-grade AI agent built using LangChain, enhanced with long-term memory via Mem0, and equipped with multiple tools such as math evaluation, text analysis, date utilities, and live weather retrieval.

This project demonstrates how to build stateful AI systems while keeping the agent itself stateless, secure, and scalable.

âœ¨ Features
ğŸ¤– LangChain Agent

Tool-calling capable agent

Clean separation of agent logic and tools

Memory-augmented system prompt

ğŸ§  Persistent Memory (Mem0)

Stores userâ€“assistant interactions

Retrieves relevant historical context

Optional memory layer (graceful degradation if disabled)

ğŸ› ï¸ Built-in Tools

Math Calculator â€“ AST-based safe arithmetic (no eval)

Text Analysis â€“ word count, character count, sentiment

Date Utility â€“ relative date calculation

Weather Tool â€“ live weather via OpenWeatherMap API

ğŸ” Secure Credential Management

Environment-variable based secrets

.env file support

Fail-fast validation for required keys

ğŸ“œ Production-Grade Logging

Structured logging across all modules

Tool-level observability

Full traceback logging for debugging

ğŸ§ª Multiple Execution Modes

Interactive chat with persistent memory

Example/demo query execution

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the Repository

git clone <repository-url>
cd <project-directory>

2ï¸âƒ£ Create a Virtual Environment (Recommended)

python -m venv venv
source venv/bin/activate (Linux / macOS)
venv\Scripts\activate (Windows)

3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

ğŸ” Environment Variables

Create a .env file in the project root with the following:

GEMINI_API_KEY=your_gemini_api_key
WEATHER_API_KEY=your_openweather_api_key
MEM0_API_KEY=your_mem0_api_key (Optional)

Credential Rules

GEMINI_API_KEY â†’ Required (LLM access)

WEATHER_API_KEY â†’ Required (Weather API)

MEM0_API_KEY â†’ Optional (Persistent memory)

If MEM0_API_KEY is missing, the application continues without memory.

ğŸš€ Running the Application

Run the application using:

python main.py

You will be prompted to choose a mode:

Interactive Chat (recommended)

Run Example Queries

ğŸ’¬ Interactive Chat Mode

Continuous conversation with long-term memory

Clean exit commands:

exit

quit

bye

q

Informational command:

clear â†’ shows number of turns

Each interaction is stored and reused intelligently

Example interaction:

You: What is my name?
Agent: Your name is Pushap.

ğŸ§ª Example Query Mode

Runs predefined demo scenarios demonstrating:

Mathematical reasoning

Multi-tool orchestration

External API usage (Weather)

Useful for:

Demos

Smoke testing

Debugging integrations

ğŸ›¡ï¸ Security & Design Principles

No hardcoded secrets

No use of eval()

AST-based safe computation

Time-bounded API requests

Graceful error handling

Stateless agent with external memory

Optional dependencies handled cleanly

ğŸ“Œ Tech Stack

Python 3.10+

LangChain

Mem0

Gemini (LLM)

OpenWeatherMap API

dotenv

requests

logging

ğŸ”® Future Enhancements

Async agent & tools

Vector tuning for memory retrieval

API caching & rate limiting

CLI flags (argparse / typer)

Unit & integration tests

Web UI (FastAPI / Streamlit)
